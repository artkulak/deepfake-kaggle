{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/timesler/fast-mtcnn-detector-45-fps-at-full-resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/94/46dcae8c061e28be31bcaa55c560cb30ee9403c9a4bb2659768ec1b9eb7d/imutils-0.5.3.tar.gz\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-cp37-none-any.whl size=25850 sha256=7fc14586dfd314caa2d5d3fbc90aa95814cc4b1f3696bebff0dfcaecbc654607\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/16/84/1f/bf88641293cda2c8be81a5c4b8ca973dd9125a6dc3767417fd\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n"
     ]
    }
   ],
   "source": [
    "! pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install facenet-pytorch (with internet use \"pip install facenet-pytorch\")\n",
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "import torch\n",
    "from imutils.video import FileVideoStream\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "filenames = glob.glob('data/videos/*.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastMTCNN(object):\n",
    "    \"\"\"Fast MTCNN implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, stride, resize=1, *args, **kwargs):\n",
    "        \"\"\"Constructor for FastMTCNN class.\n",
    "        \n",
    "        Arguments:\n",
    "            stride (int): The detection stride. Fac8es will be detected every `stride` frames\n",
    "                and remembered for `stride-1` frames.\n",
    "        \n",
    "        Keyword arguments:\n",
    "            resize (float): Fractional frame scaling. [default: {1}]\n",
    "            *args: Arguments to pass to the MTCNN constructor. See help(MTCNN).\n",
    "            **kwargs: Keyword arguments to pass to the MTCNN constructor. See help(MTCNN).\n",
    "        \"\"\"\n",
    "        self.stride = stride\n",
    "        self.resize = resize\n",
    "        self.mtcnn = MTCNN(*args, **kwargs)\n",
    "        \n",
    "    def __call__(self, frames):\n",
    "        \"\"\"Detect faces in frames using strided MTCNN.\"\"\"\n",
    "        if self.resize != 1:\n",
    "            frames = [f.resize([int(d * self.resize) for d in f.size]) for f in frames]\n",
    "                      \n",
    "        boxes, probs = self.mtcnn.detect(frames[::self.stride])\n",
    "\n",
    "        faces = []\n",
    "        for i, frame in enumerate(frames):\n",
    "            box_ind = int(i / self.stride)\n",
    "            if boxes[box_ind] is None:\n",
    "                continue\n",
    "            for box in boxes[box_ind]:\n",
    "                faces.append(frame.crop(box))\n",
    "        \n",
    "        return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "FACES_PATH = 'faces/'\n",
    "try:\n",
    "    shutil.rmtree(FACES_PATH)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "try: \n",
    "    os.mkdir(FACES_PATH)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def run_detection(fast_mtcnn, filenames):\n",
    "    \n",
    "    frames = []\n",
    "    frames_processed = 0\n",
    "    faces_detected = 0\n",
    "    batch_size = 60\n",
    "    framePass = 5\n",
    "    start = time.time()\n",
    "\n",
    "    for filename in tqdm(filenames):\n",
    "        try: \n",
    "            os.mkdir(FACES_PATH + f'''{filename.split('/')[-1]}/''')\n",
    "        except:\n",
    "            pass\n",
    "        v_cap = FileVideoStream(filename).start()\n",
    "        v_len = int(v_cap.stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        for j in range(v_len):\n",
    "            frame = v_cap.read()\n",
    "            if j % framePass != 0 and j > 0:\n",
    "                continue\n",
    "            try:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = Image.fromarray(frame)\n",
    "            except:\n",
    "                break\n",
    "            \n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) >= batch_size or j == v_len - 1:\n",
    "                try:\n",
    "                    faces = fast_mtcnn(frames)\n",
    "                except:\n",
    "                    break\n",
    "                \n",
    "                for index, face in enumerate(faces):\n",
    "                    face.save(FACES_PATH + f'''{filename.split('/')[-1]}/{index * framePass}.png''')\n",
    "                    \n",
    "                frames_processed += len(frames)\n",
    "                faces_detected += len(faces)\n",
    "                frames = []\n",
    "\n",
    "                print(\n",
    "                    f'Frames per second: {frames_processed / (time.time() - start):.3f},',\n",
    "                    f'faces detected: {faces_detected}\\r',\n",
    "                    end=''\n",
    "                )\n",
    "\n",
    "        v_cap.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_mtcnn = FastMTCNN(\n",
    "#     stride=4,\n",
    "#     resize=1,\n",
    "#     margin=14,\n",
    "#     factor=0.6,\n",
    "#     keep_all=True,\n",
    "#     device=device\n",
    "# )\n",
    "# run_detection(fast_mtcnn, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af2d381a6c642b4980a0b68708e1b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second: 22.922, faces detected: 6876\n"
     ]
    }
   ],
   "source": [
    "fast_mtcnn = FastMTCNN(\n",
    "    stride=4,\n",
    "    resize=0.5,\n",
    "    margin=14,\n",
    "    factor=0.6,\n",
    "    keep_all=True,\n",
    "    device=device\n",
    ")\n",
    "run_detection(fast_mtcnn, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
