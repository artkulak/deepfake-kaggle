{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-21 18:53:36--  https://www.kaggle.com/c/16880/datadownload/dfdc_train_part_49.zip\n",
      "Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n",
      "Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://storage.googleapis.com/kaggle-competitions-detached-data/16880/dfdc_train_part_49.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1582570416&Signature=jvejWqeiAFTXkY4CqjAkCrXKyhqWwCrJgbmVMkerr5LlJz0KZhRu1ZZJhNoNEDUdoGMljVfbQwZ1sexue0o9b7ta1c7Tin4NJ1316Ul12D63pxUHTCKhk4vVGkkkqj7PDQxYrOItS%2BGo0TYEhI55mQBGwyoQ%2FO1%2B3oM1S0Uoxxe4NhU0iRcRpKuz9kzDkXD588hcfOnydVYn2DMzU1vykrbKdXoRYvPayaR43PsDZil6eDa%2BOCTqv7fQhioLFHDf%2Bbe8GvtOHMJuUsUB4Qyy1ekiqDLBzg7wzGoklk1tA9yE5VmMFWD56zQUhztAICMyIT%2BirQ663IvAEs8YPrjgQA%3D%3D [following]\n",
      "--2020-02-21 18:53:36--  https://storage.googleapis.com/kaggle-competitions-detached-data/16880/dfdc_train_part_49.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1582570416&Signature=jvejWqeiAFTXkY4CqjAkCrXKyhqWwCrJgbmVMkerr5LlJz0KZhRu1ZZJhNoNEDUdoGMljVfbQwZ1sexue0o9b7ta1c7Tin4NJ1316Ul12D63pxUHTCKhk4vVGkkkqj7PDQxYrOItS%2BGo0TYEhI55mQBGwyoQ%2FO1%2B3oM1S0Uoxxe4NhU0iRcRpKuz9kzDkXD588hcfOnydVYn2DMzU1vykrbKdXoRYvPayaR43PsDZil6eDa%2BOCTqv7fQhioLFHDf%2Bbe8GvtOHMJuUsUB4Qyy1ekiqDLBzg7wzGoklk1tA9yE5VmMFWD56zQUhztAICMyIT%2BirQ663IvAEs8YPrjgQA%3D%3D\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 2607:f8b0:400e:c08::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9836616490 (9.2G) [application/zip]\n",
      "Saving to: ‘dfdc_train_part_49.zip.1’\n",
      "\n",
      "dfdc_train_part_49. 100%[===================>]   9.16G  85.8MB/s    in 2m 29s  \n",
      "\n",
      "2020-02-21 18:56:05 (62.9 MB/s) - ‘dfdc_train_part_49.zip.1’ saved [9836616490/9836616490]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --load-cookies cookies.txt https://www.kaggle.com/c/16880/datadownload/dfdc_train_all.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/jupyter/dfdc_train_all.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [2:05:59<05:11, 155.85s/it]  "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "home = ''\n",
    "def get_zipfiles(home):\n",
    "    list_files = []\n",
    "    for filename in os.listdir(home):\n",
    "        if filename.endswith(\".zip\"): \n",
    "            list_files.append(os.path.join(home, filename))\n",
    "    return list_files\n",
    "\n",
    "zipfiles = get_zipfiles('/home/jupyter/')\n",
    "zipfiles.sort()\n",
    "\n",
    "for zipfile in zipfiles:\n",
    "    print(f'Extracting {zipfile}...')\n",
    "    with ZipFile(file=zipfile) as zip_file:\n",
    "        for file in tqdm(iterable=zip_file.namelist(), total=len(zip_file.namelist())):\n",
    "            zip_file.extract(member=file, path = '/home/jupyter/data/')\n",
    "\n",
    "    os.remove(zipfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started extracting dfdc_train_part_08\n",
      "Started extracting dfdc_train_part_04\n",
      "Started extracting dfdc_train_part_00\n",
      "Started extracting dfdc_train_part_12\n",
      "Finished extracting and deleted dfdc_train_part_04\n",
      "Started extracting dfdc_train_part_05\n",
      "Finished extracting and deleted dfdc_train_part_12\n",
      "Started extracting dfdc_train_part_13\n",
      "Finished extracting and deleted dfdc_train_part_08\n",
      "Started extracting dfdc_train_part_09\n",
      "Finished extracting and deleted dfdc_train_part_00\n",
      "Started extracting dfdc_train_part_01\n",
      "Finished extracting and deleted dfdc_train_part_05\n",
      "Started extracting dfdc_train_part_06\n",
      "Finished extracting and deleted dfdc_train_part_13\n",
      "Started extracting dfdc_train_part_14\n",
      "Finished extracting and deleted dfdc_train_part_09\n",
      "Started extracting dfdc_train_part_10\n",
      "Finished extracting and deleted dfdc_train_part_01\n",
      "Started extracting dfdc_train_part_02\n",
      "Finished extracting and deleted dfdc_train_part_14\n",
      "Started extracting dfdc_train_part_15\n",
      "Finished extracting and deleted dfdc_train_part_06\n",
      "Started extracting dfdc_train_part_07\n",
      "Finished extracting and deleted dfdc_train_part_10\n",
      "Started extracting dfdc_train_part_11\n",
      "Finished extracting and deleted dfdc_train_part_02\n",
      "Started extracting dfdc_train_part_03\n",
      "Finished extracting and deleted dfdc_train_part_15\n",
      "Started extracting dfdc_train_part_16\n",
      "Finished extracting and deleted dfdc_train_part_11\n",
      "Started extracting dfdc_train_part_20\n",
      "Finished extracting and deleted dfdc_train_part_07\n",
      "Started extracting dfdc_train_part_24\n",
      "Finished extracting and deleted dfdc_train_part_03\n",
      "Started extracting dfdc_train_part_28\n",
      "Finished extracting and deleted dfdc_train_part_16\n",
      "Started extracting dfdc_train_part_17\n",
      "Finished extracting and deleted dfdc_train_part_20\n",
      "Started extracting dfdc_train_part_21\n",
      "Finished extracting and deleted dfdc_train_part_24\n",
      "Started extracting dfdc_train_part_25\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "from zipfile import ZipFile                                                                                                                                       \n",
    "import logging\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    os.mkdir('/home/jupyter/data/metadata')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir('/home/jupyter/data/videos')\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "\n",
    "DATA = Path('/home/jupyter/data')\n",
    "DEST = Path('/home/jupyter/data')\n",
    "logging.basicConfig(filename='extract.log', level=logging.INFO)\n",
    "zipfiles = sorted(list(DATA.glob('dfdc_train_part_*.zip')), key=lambda x: x.stem)\n",
    "\n",
    "def extract_zip(zipfile: Union[str, Path])->None:\n",
    "    print(f'Started extracting {zipfile.stem}')\n",
    "    zip_no = zipfile.stem[-2:]\n",
    "    with ZipFile(zipfile) as zip_file:\n",
    "        for file in [Path(fn) for fn in zip_file.namelist()]:\n",
    "            try:\n",
    "                zip_info = zip_file.getinfo(str(file))\n",
    "                if file.suffix == '.json':\n",
    "                    zip_info.filename = f'{file.stem}_{zip_no}{file.suffix}'\n",
    "                    dest = DEST/'metadata'\n",
    "                else:\n",
    "                    zip_info.filename = file.name\n",
    "                    dest = DEST/'videos'\n",
    "                zip_file.extract(zip_info, path=dest)\n",
    "            except:\n",
    "                logging.error(f'error extracing {file.stem} from {zipfile.stem}')\n",
    "\n",
    "    # add zip file number to metadata\n",
    "    meta_fn = DEST/'metadata'/f'metadata_{zip_no}.json'\n",
    "    df_meta = pd.read_json(meta_fn).T\n",
    "    df_meta['zip_no'] = zip_no\n",
    "    df_meta.to_json(meta_fn)\n",
    "\n",
    "    # delete zip file\n",
    "    zipfile.unlink()\n",
    "\n",
    "    print(f'Finished extracting and deleted {zipfile.stem}')\n",
    "    logging.info(f'Finished extracting and deleted {zipfile.stem}')\n",
    "\n",
    "start = int(time.time())\n",
    "with multiprocessing.Pool() as pool: # use all cores available\n",
    "    pool.map(extract_zip, zipfiles)\n",
    "\n",
    "logging.info(f\"Extracted all zip files in {int(time.time()) - start} seconds!\")\n",
    "print(f\"Extracted all zip files in {int(time.time()) - start} seconds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
